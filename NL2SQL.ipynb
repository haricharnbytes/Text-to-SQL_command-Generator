{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6ab20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4dcb034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading API key\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d24b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM init\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ab1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert-level AI assistant.\n",
    "\n",
    "Your task is to provide a clear, accurate, and well-structured answer to the userâ€™s question.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Be precise, factual, and concise.\n",
    "\n",
    "Organize your response with clear headings and bullet points where appropriate.\n",
    "\n",
    "Provide step-by-step explanations when the topic requires reasoning or processes.\n",
    "\n",
    "If the question is ambiguous, state your assumption before answering.\n",
    "\n",
    "If you are uncertain about any information, clearly acknowledge it.\n",
    "\n",
    "Avoid unnecessary filler, repetition, or vague statements.\n",
    "\n",
    "Prioritize clarity, logical flow, and completeness.\n",
    "\n",
    "User Question:\n",
    "\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "qa_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95209c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
